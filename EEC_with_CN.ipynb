{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEC with CN",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SebastianJia/nlp_research_conceptor/blob/master/EEC_with_CN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WQJS8yEwygVb",
        "colab_type": "code",
        "outputId": "cb0768f0-53c1-4b53-b9c0-4d3156bc34b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.saifmohammad.com/WebDocs/EEC/Equity-Evaluation-Corpus.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-28 01:32:06--  http://www.saifmohammad.com/WebDocs/EEC/Equity-Evaluation-Corpus.zip\n",
            "Resolving www.saifmohammad.com (www.saifmohammad.com)... 192.185.17.122\n",
            "Connecting to www.saifmohammad.com (www.saifmohammad.com)|192.185.17.122|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102568 (100K) [application/zip]\n",
            "Saving to: ‘Equity-Evaluation-Corpus.zip’\n",
            "\n",
            "Equity-Evaluation-C 100%[===================>] 100.16K   575KB/s    in 0.2s    \n",
            "\n",
            "2019-02-28 01:32:06 (575 KB/s) - ‘Equity-Evaluation-Corpus.zip’ saved [102568/102568]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Le67qqg0ypdn",
        "colab_type": "code",
        "outputId": "d63ce411-6bc8-4b72-cd92-d0b2e91deb20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip Equity-Evaluation-Corpus.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Equity-Evaluation-Corpus.zip\n",
            "  inflating: Equity-Evaluation-Corpus.csv  \n",
            "  inflating: README.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LdMrdkW5ypSC",
        "colab_type": "code",
        "outputId": "76c78e54-32ff-456d-b828-8149f547fdd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy, requests, codecs, os, re, nltk, itertools, csv\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "import tensorflow as tf\n",
        "from scipy.stats import spearmanr\n",
        "import pandas as pd\n",
        "import functools as ft\n",
        "import os\n",
        "import io\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "07NMbgS0y5ji",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EEC = pd.read_csv('/content/Equity-Evaluation-Corpus.csv', header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zHGlOXkfzHYL",
        "colab_type": "code",
        "outputId": "523ef208-819c-4723-c9ab-2dd62795a722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "EEC[0:5]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Template</th>\n",
              "      <th>Person</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Race</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Emotion word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-En-mystery-05498</td>\n",
              "      <td>Alonzo feels angry.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-En-mystery-11722</td>\n",
              "      <td>Alonzo feels furious.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>furious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-En-mystery-11364</td>\n",
              "      <td>Alonzo feels irritated.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>irritated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-En-mystery-14320</td>\n",
              "      <td>Alonzo feels enraged.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>enraged</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-En-mystery-14114</td>\n",
              "      <td>Alonzo feels annoyed.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>annoyed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      ID                 Sentence  \\\n",
              "0  2018-En-mystery-05498      Alonzo feels angry.   \n",
              "1  2018-En-mystery-11722    Alonzo feels furious.   \n",
              "2  2018-En-mystery-11364  Alonzo feels irritated.   \n",
              "3  2018-En-mystery-14320    Alonzo feels enraged.   \n",
              "4  2018-En-mystery-14114    Alonzo feels annoyed.   \n",
              "\n",
              "                                 Template  Person Gender              Race  \\\n",
              "0  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "1  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "2  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "3  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "4  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "\n",
              "  Emotion Emotion word  \n",
              "0   anger        angry  \n",
              "1   anger      furious  \n",
              "2   anger    irritated  \n",
              "3   anger      enraged  \n",
              "4   anger      annoyed  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "metadata": {
        "id": "7PipGcPqDAsp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load GloVe embeddings"
      ]
    },
    {
      "metadata": {
        "id": "EaIytYquTinV",
        "colab_type": "code",
        "outputId": "02ae7702-aa60-4104-a861-4929508b3b35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q gdown\n",
        "!gdown https://drive.google.com/uc?id=1Ty2exMyi-XOufY-v81RJfiPvnintHuy2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ty2exMyi-XOufY-v81RJfiPvnintHuy2\n",
            "To: /content/gensim_glove.840B.300d.txt.bin\n",
            "2.65GB [00:49, 53.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iERp98e_DE0T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Word2vec embeddings\n",
        "CN performed better using word2vec embeddings. For all 4 sentiments, CN showed improvements on debiasing gender bias.\n",
        "If using GloVe embeddings, CN showed improvements on anger, fear and joy. For the sentiment 'sadness', CN gave a higher gender difference. However, by my observations, results can be improved if using more female and male names to find conceptors. So with a larger name datasets, the results of 'sadness' may also show improvements on debiasing."
      ]
    },
    {
      "metadata": {
        "id": "89VbGhaRywxU",
        "colab_type": "code",
        "outputId": "cfd98798-bd10-4936-857a-cf6b2512d9a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "1.65GB [00:39, 42.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ilnFmeJ22HSL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!gunzip /content/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mk0C_cga8FVP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load fasttext"
      ]
    },
    {
      "metadata": {
        "id": "PvnD-qf98HIT",
        "colab_type": "code",
        "outputId": "0df81f98-986c-4099-906c-9569f793f847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1Zl6a75Ybf8do9uupmrJWKQMnvqqme4fh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Zl6a75Ybf8do9uupmrJWKQMnvqqme4fh\n",
            "To: /content/fasttext.bin\n",
            "2.42GB [00:42, 56.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VdnZkDWH8cqU",
        "colab_type": "code",
        "outputId": "f0bc1ef2-329e-492c-ef48-9aff1a0f4f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "fasttext = KeyedVectors.load_word2vec_format('/content/' + 'fasttext.bin', binary=True)\n",
        "print('The fasttext embedding has been loaded!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The fasttext embedding has been loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s7NSiKG2DN2J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load male and female name lists\n"
      ]
    },
    {
      "metadata": {
        "id": "cIyTozuW3V2H",
        "colab_type": "code",
        "outputId": "8a1980d2-88cd-4294-f91f-fe50fbcba2f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/male.txt\n",
        "!wget https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/female.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-28 01:38:36--  https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/male.txt\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20466 (20K) [text/plain]\n",
            "Saving to: ‘male.txt’\n",
            "\n",
            "male.txt            100%[===================>]  19.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-02-28 01:38:36 (241 MB/s) - ‘male.txt’ saved [20466/20466]\n",
            "\n",
            "--2019-02-28 01:38:37--  https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/female.txt\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35751 (35K) [text/plain]\n",
            "Saving to: ‘female.txt’\n",
            "\n",
            "female.txt          100%[===================>]  34.91K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-02-28 01:38:37 (469 KB/s) - ‘female.txt’ saved [35751/35751]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Du8iVH8ZBApb",
        "colab_type": "code",
        "outputId": "99ad6603-7e40-4a11-bc37-b98b6d1386b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/mbejda/61eb488cec271086632d/raw/6340b8045b28c2abc0b1d44cfbc80f40284ef890/Black-Male-Names.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-28 02:52:14--  https://gist.githubusercontent.com/mbejda/61eb488cec271086632d/raw/6340b8045b28c2abc0b1d44cfbc80f40284ef890/Black-Male-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 921600 (900K) [text/plain]\n",
            "Saving to: ‘Black-Male-Names.csv’\n",
            "\n",
            "\rBlack-Male-Names.cs   0%[                    ]       0  --.-KB/s               \rBlack-Male-Names.cs 100%[===================>] 900.00K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-02-28 02:52:14 (20.8 MB/s) - ‘Black-Male-Names.csv’ saved [921600/921600]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XkgU1s9uBFzD",
        "colab_type": "code",
        "outputId": "8dfbb726-59c0-4ea6-b630-de784e7f7ef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/mbejda/6c2293ba3333b7e76269/raw/60aa0c95e8ee9b11b915a26f47480fef5c3203ed/White-Male-Names.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-28 02:52:44--  https://gist.githubusercontent.com/mbejda/6c2293ba3333b7e76269/raw/60aa0c95e8ee9b11b915a26f47480fef5c3203ed/White-Male-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1149042 (1.1M) [text/plain]\n",
            "Saving to: ‘White-Male-Names.csv’\n",
            "\n",
            "\rWhite-Male-Names.cs   0%[                    ]       0  --.-KB/s               \rWhite-Male-Names.cs 100%[===================>]   1.10M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-02-28 02:52:44 (24.9 MB/s) - ‘White-Male-Names.csv’ saved [1149042/1149042]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aMwQpmkxEWBv",
        "colab_type": "code",
        "outputId": "050fef81-54d8-4e35-a3c4-189945ab5c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/mbejda/26ad0574eda7fca78573/raw/6936d1a8f5fa5220f2f60a51a06a35b172c50f93/White-Female-Names.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-28 03:08:45--  https://gist.githubusercontent.com/mbejda/26ad0574eda7fca78573/raw/6936d1a8f5fa5220f2f60a51a06a35b172c50f93/White-Female-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121903 (119K) [text/plain]\n",
            "Saving to: ‘White-Female-Names.csv’\n",
            "\n",
            "\rWhite-Female-Names.   0%[                    ]       0  --.-KB/s               \rWhite-Female-Names. 100%[===================>] 119.05K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-02-28 03:08:45 (5.25 MB/s) - ‘White-Female-Names.csv’ saved [121903/121903]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zlhooFTdEXIC",
        "colab_type": "code",
        "outputId": "b6f7ab0f-8ac8-40b0-b217-54ab637f83b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/mbejda/9dc89056005a689a6456/raw/bb6ef2375f1289d0ef10dbd8e9469670ac23ceab/Black-Female-Names.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-28 03:08:49--  https://gist.githubusercontent.com/mbejda/9dc89056005a689a6456/raw/bb6ef2375f1289d0ef10dbd8e9469670ac23ceab/Black-Female-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64757 (63K) [text/plain]\n",
            "Saving to: ‘Black-Female-Names.csv’\n",
            "\n",
            "\rBlack-Female-Names.   0%[                    ]       0  --.-KB/s               \rBlack-Female-Names. 100%[===================>]  63.24K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-02-28 03:08:50 (4.26 MB/s) - ‘Black-Female-Names.csv’ saved [64757/64757]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LC3JKbM1Xmkx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "glove = KeyedVectors.load_word2vec_format('/content/' + 'gensim_glove.840B.300d.txt.bin', binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DeCv7ip13uN6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word2vec = KeyedVectors.load_word2vec_format('/content/' + 'GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PXx6x2vGEshx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get frequency list (used in calculating sentence embeddings)"
      ]
    },
    {
      "metadata": {
        "id": "MWwGFIWGXqU7",
        "colab_type": "code",
        "outputId": "0da2d4a8-9ca3-464d-daac-32b27740eb04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PrincetonML/SIF"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'SIF' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NRf-8VO3X0y7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wikiWordsPath = '/content' + '/SIF/auxiliary_data/enwiki_vocab_min200.txt' # https://github.com/PrincetonML/SIF/blob/master/auxiliary_data/enwiki_vocab_min200.txt\n",
        "\n",
        "frequencies = {}\n",
        "with open(wikiWordsPath, \"r+\") as f_in:\n",
        "    for line in f_in:\n",
        "        frequencies[line.split(' ')[0]] = float(line.split(' ')[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZi3h1qOBSap",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load white/black names"
      ]
    },
    {
      "metadata": {
        "id": "dpuRepkwM0Ma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-V9S_T5FBXLm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "f = open('/content/White-Male-Names.csv', 'r+')\n",
        "f.readline()\n",
        "for line in f:\n",
        "  word_list.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BjMZUac-B4ga",
        "colab_type": "code",
        "outputId": "b843ff83-7cb9-4f33-b872-8bf9ff4d4bf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79129"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "metadata": {
        "id": "Joae0NAZCVbd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open('/content/Black-Male-Names.csv', 'r+')\n",
        "f.readline()\n",
        "for line in f:\n",
        "  word_list.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rrNPXn6YCcbM",
        "colab_type": "code",
        "outputId": "505e2651-3ddd-4421-ca31-244a3b9102c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79129"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "IKdc4FQcE4s3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open('/content/White-Female-Names.csv', 'r+')\n",
        "f.readline()\n",
        "for line in f:\n",
        "  word_list.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YrJhXzkPFbgn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open('/content/Black-Female-Names.csv', 'r+')\n",
        "f.readline()\n",
        "for line in f:\n",
        "  word_list.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4vA6OIHCFgeI",
        "colab_type": "code",
        "outputId": "22037792-7e70-4bc9-cb0c-88572041201d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7038"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "metadata": {
        "id": "TWXuqqFmE1_Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load gender names"
      ]
    },
    {
      "metadata": {
        "id": "Rog_F2625pyG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load names from larger name dataset\n",
        "f = open('/content/male.txt', 'r+')\n",
        "i = 0\n",
        "word_list= []\n",
        "for line in f:\n",
        "  i+=1\n",
        "  if i < 7:\n",
        "    continue\n",
        "  token = line.split()\n",
        "  word_list.append(token[0])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D75vc0Q86cIU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load names from larger name dataset\n",
        "f = open('/content/female.txt', 'r+')\n",
        "i = 0\n",
        "for line in f:\n",
        "  i+=1\n",
        "  if i < 7:\n",
        "    continue\n",
        "  token = line.split()\n",
        "  word_list.append(token[0])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a1pLLoV-6gSv",
        "colab_type": "code",
        "outputId": "a254dadf-fec7-40d1-a6e0-6ffcaf0c70bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "metadata": {
        "id": "aVKauBMi6gJE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open('/content/name.txt', 'r+')\n",
        "#word_list = []\n",
        "for line in f:\n",
        "  for item in line.rstrip().split(' '):\n",
        "    word_list.append(item)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "shXdpgjByXkK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0dFRyTKXc4WR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Racial Names"
      ]
    },
    {
      "metadata": {
        "id": "y4p870_Oc7hC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# These are names in the paper\n",
        "word_list = ['Alonzo', 'Jamel', 'Alphonse', 'Jerome', 'Leroy', 'Torrance',\n",
        "       'Darnell', 'Lamar', 'Malik', 'Terrence', 'Adam', 'Harry', 'Josh',\n",
        "       'Roger', 'Alan', 'Frank', 'Justin', 'Ryan', 'Andrew', 'Jack','Nichelle',\n",
        "       'Shereen', 'Ebony', 'Latisha', 'Shaniqua', 'Jasmine', 'Tanisha',\n",
        "       'Tia', 'Lakisha', 'Latoya', 'Amanda', 'Courtney', 'Heather',\n",
        "       'Melanie', 'Katie', 'Betsy', 'Kristin', 'Nancy', 'Stephanie',\n",
        "       'Ellen']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q7Q_CBQ6dkUs",
        "colab_type": "code",
        "outputId": "7d14b76e-3bc2-49b6-b4bf-77615446cfd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "EEC['Person'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Alonzo', 'Jamel', 'Alphonse', 'Jerome', 'Leroy', 'Torrance',\n",
              "       'Darnell', 'Lamar', 'Malik', 'Terrence', 'Adam', 'Harry', 'Josh',\n",
              "       'Roger', 'Alan', 'Frank', 'Justin', 'Ryan', 'Andrew', 'Jack', 'he',\n",
              "       'this man', 'this boy', 'my brother', 'my son', 'my husband',\n",
              "       'my boyfriend', 'my father', 'my uncle', 'my dad', 'Nichelle',\n",
              "       'Shereen', 'Ebony', 'Latisha', 'Shaniqua', 'Jasmine', 'Tanisha',\n",
              "       'Tia', 'Lakisha', 'Latoya', 'Amanda', 'Courtney', 'Heather',\n",
              "       'Melanie', 'Katie', 'Betsy', 'Kristin', 'Nancy', 'Stephanie',\n",
              "       'Ellen', 'she', 'this woman', 'this girl', 'my sister',\n",
              "       'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt',\n",
              "       'my mom', 'him', 'her'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "HjvwEWHd6wmQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For GloVe data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([glove[word] for word in word_list if word in glove.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vNW92mNQ_B_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For word2vec data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([word2vec[word] for word in word_list if word in word2vec.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_JXi_dnD7EkN",
        "colab_type": "code",
        "outputId": "76763cc8-7733-4d58-84dd-0012c1b29207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cn_embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7099, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "-wU25Uq1vdUv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Sentence embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6iZFRcuzwmZ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "class Sentence:\n",
        "    \n",
        "    def __init__(self, sentence):\n",
        "        self.raw = sentence\n",
        "        normalized_sentence = sentence.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
        "        self.tokens = [t.lower() for t in nltk.word_tokenize(normalized_sentence)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Itl-QRYavh9n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Raw Sentence Embeddings\n",
        "from sklearn.decomposition import TruncatedSVD, randomized_svd\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def run_sif_benchmark(sentiment, sent1, sent2, model_str, freqs={}, a=0.001): \n",
        "    total_freq = sum(freqs.values())\n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        "#    sen_list = EEC[EEC['Emotion']==sen]['Emotion word'].unique()\n",
        "    #average sentiment embedding based on several emotional words of the same sentiment\n",
        "#    sen_embeddings = np.average([model[item] for item in sen_list if item in model.vocab], axis=0)    \n",
        "    tokens1 =  sent1.tokens\n",
        "    tokens2 =  sent2.tokens\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "        \n",
        "    embedding1 = np.array(np.average([model[token] for token in tokens1], axis=0, weights=weights1))\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 = np.array(np.average([model[token] for token in tokens2], axis=0, weights=weights2))\n",
        "    embedding2/= norm(embedding2)\n",
        "    proj1 = embedding1.dot(model[sentiment])/norm(model[sentiment])\n",
        "    proj2 = embedding2.dot(model[sentiment])/norm(model[sentiment])\n",
        "\n",
        "\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m6KBvMZJGRGt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#CN Sentence Embeddings\n",
        "def run_conceptor_benchmark(sentiment,sent1, sent2, model_str, freqs={}, a=0.001, alpha =2): \n",
        "    total_freq = sum(freqs.values())\n",
        "    \n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        " #   sen_list = EEC[EEC['Emotion']==sen]['Emotion word'].unique()\n",
        " #   sen_embeddings = np.average([model[item] for item in sen_list if item in model.vocab], axis = 0) \n",
        " #   print(sen_embeddings)\n",
        "    # SIF requires us to first collect all sentence embeddings and then perform \n",
        "    # common component analysis.\n",
        "        \n",
        "    tokens1 =  sent1.tokens\n",
        "    tokens2 =  sent2.tokens\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "        \n",
        "    embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n",
        "    embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n",
        "        \n",
        "\n",
        "    R = (cn_embeddings.T).dot(cn_embeddings) / cn_embeddings.shape[0]\n",
        "\n",
        "    \n",
        "    \n",
        "    C = R @ np.linalg.inv (R + alpha ** (-2) * np.eye(300))# calculate the conceptor matrix\n",
        "    \n",
        "    negC = np.eye(300) - C\n",
        "    #negC = np.eye(300) - SWC[model_str]\n",
        "    \n",
        "    \n",
        "    embedding1 = negC.dot(embedding1.T).T\n",
        "    embedding2 = negC.dot(embedding2.T).T\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 /= norm(embedding2)\n",
        "    proj1 = embedding1.dot(model[sentiment])/norm(model[sentiment])\n",
        "    proj2 = embedding2.dot(model[sentiment])/norm(model[sentiment])\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gtceGUSqxVPt",
        "colab_type": "code",
        "outputId": "3fbfa334-5baf-4b5b-d637-e71dd041f39c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='male') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  print('race difference on Raw and CN data:')\n",
        "  print(abs((sum(aa)-sum(ea))/len(aa)), abs((sum(aa_cn)-sum(ea_cn))/len(aa_cn)))\n",
        "  print('t value and p value :')\n",
        "  print(p1,p2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "race difference on Raw and CN data:\n",
            "0.034567342436660625 0.012273898802537408\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=13.849455809836892, pvalue=4.572745056474093e-35) Ttest_relResult(statistic=6.669230653088165, pvalue=1.0084986003378286e-10)\n",
            "race difference on Raw and CN data:\n",
            "0.024553912881999745 0.0011690208544382586\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=8.261900036278009, pvalue=3.0162583244598363e-15) Ttest_relResult(statistic=-0.5469156271130736, pvalue=0.5847862167151139)\n",
            "race difference on Raw and CN data:\n",
            "0.008068057572518187 0.0031396870145185777\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=5.40095963161286, pvalue=1.2286794299439083e-07) Ttest_relResult(statistic=2.350573923835871, pvalue=0.019300517055452857)\n",
            "race difference on Raw and CN data:\n",
            "0.028750490054312083 0.017983265350474693\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=19.54372892885523, pvalue=5.545094747635267e-58) Ttest_relResult(statistic=15.745114359232701, pvalue=1.4009279830328533e-42)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nqBE6INvU93r",
        "colab_type": "code",
        "outputId": "b8bfcc5f-929e-4c63-d2cc-9c5303bdd746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='female') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  print('race difference on Raw and CN data:')\n",
        "  print(abs((sum(aa)-sum(ea))/len(aa)), abs((sum(aa_cn)-sum(ea_cn))/len(aa_cn)))\n",
        "  print('t value and p value :')\n",
        "  print(p1,p2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "race difference on Raw and CN data:\n",
            "0.034567342436660625 0.009929673733909112\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=13.849455809836892, pvalue=4.572745056474093e-35) Ttest_relResult(statistic=5.564122085509471, pvalue=5.2552721196549e-08)\n",
            "race difference on Raw and CN data:\n",
            "0.024553912881999745 0.004532087437763721\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=8.261900036278009, pvalue=3.0162583244598363e-15) Ttest_relResult(statistic=-2.2142666139122973, pvalue=0.02745618826465397)\n",
            "race difference on Raw and CN data:\n",
            "0.008068057572518187 0.0024199706160516954\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=5.40095963161286, pvalue=1.2286794299439083e-07) Ttest_relResult(statistic=1.979455935817103, pvalue=0.048550112213081746)\n",
            "race difference on Raw and CN data:\n",
            "0.028750490054312083 0.015889093653560168\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=19.54372892885523, pvalue=5.545094747635267e-58) Ttest_relResult(statistic=15.293601422475524, pvalue=9.001126995726789e-41)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "34-TlO--C0QR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Add extra names and pronouns\n",
        "#load names and pronouns from EEC\n",
        "name_pron = list(set(EEC['Person']))\n",
        "for item in name_pron:\n",
        "  num = item.rstrip().split(' ')\n",
        "  if len(num)!=1:\n",
        "    word_list.append(num[1])\n",
        "  else:\n",
        "    word_list.append(num[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M-FdCUanC7mh",
        "colab_type": "code",
        "outputId": "cfe86c43-c237-4ead-8e93-05b31a0d55fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8068"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "shWbzDiwDVvp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cn_embeddings = []\n",
        "cn_embeddings.append([word2vec[word] for word in word_list if word in word2vec.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RumpnNDpq57m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For GloVe data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([glove[word] for word in word_list if word in glove.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PavqP7YWCsHG",
        "colab_type": "code",
        "outputId": "a5e23854-6b58-4abc-cd8d-46787c6fec55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') & (sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European') & (sent_sent['Gender']=='male')]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  print('race difference on Raw and CN data:')\n",
        "  print(abs((sum(aa)-sum(ea))/len(aa)), abs((sum(aa_cn)-sum(ea_cn))/len(aa_cn)))\n",
        "  print('t value and p value :')\n",
        "  print(p1,p2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "race difference on Raw and CN data:\n",
            "0.06474567235189908 0.04209460345394559\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-39.22921469721085, pvalue=5.4672329176397445e-130) Ttest_relResult(statistic=-28.314120707505623, pvalue=1.9678842743317127e-92)\n",
            "race difference on Raw and CN data:\n",
            "0.09000543647654273 0.057980282036428514\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-53.68250229510699, pvalue=1.0070693011474893e-170) Ttest_relResult(statistic=-45.070483345589906, pvalue=1.4577893766486125e-147)\n",
            "race difference on Raw and CN data:\n",
            "0.07573256126403977 0.053055973290192356\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-36.3533563736058, pvalue=1.0329660357653552e-120) Ttest_relResult(statistic=-33.692193529495704, pvalue=9.716275805084765e-112)\n",
            "race difference on Raw and CN data:\n",
            "0.0338204970991427 0.0341980605595707\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-22.533353932748184, pvalue=4.8170981260922015e-70) Ttest_relResult(statistic=-26.08957574516559, pvalue=5.333202384902776e-84)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ifykhtkiVCic",
        "colab_type": "code",
        "outputId": "56e326c4-81f1-4744-8b2e-6b43c46cd6df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') & (sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European') & (sent_sent['Gender']=='female')]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  print('race difference on Raw and CN data:')\n",
        "  print(abs((sum(aa)-sum(ea))/len(aa)), abs((sum(aa_cn)-sum(ea_cn))/len(aa_cn)))\n",
        "  print('t value and p value :')\n",
        "  print(p1,p2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "race difference on Raw and CN data:\n",
            "0.05750085090959179 0.04480440422230783\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-25.594524554962252, pvalue=4.332972426975255e-82) Ttest_relResult(statistic=-18.32019442951023, pvalue=5.245264394890672e-53)\n",
            "race difference on Raw and CN data:\n",
            "0.08173955082869465 0.05799314785779286\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-33.008121817138765, pvalue=2.2699881351783204e-109) Ttest_relResult(statistic=-25.057504910556165, pvalue=5.264660627277734e-80)\n",
            "race difference on Raw and CN data:\n",
            "0.0986180293952588 0.04440255589506588\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-29.708213522391834, pvalue=1.3788509973672255e-97) Ttest_relResult(statistic=-21.810645483064388, pvalue=3.782584028784904e-67)\n",
            "race difference on Raw and CN data:\n",
            "0.03154974838978562 0.03211823048496119\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-15.01815228780253, pvalue=1.1281620467502544e-39) Ttest_relResult(statistic=-14.605255011684568, pvalue=4.903265518921864e-38)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "04hAVdzO80en",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For Fasttext data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([fasttext[word] for word in word_list if word in fasttext.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MLYZ68Q6vXwP",
        "colab_type": "code",
        "outputId": "7be486e6-a3fe-449e-b55a-8ef1eadc1c31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') & (sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European') & (sent_sent['Gender']=='male')]\n",
        "  #print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  print('race difference on Raw and CN data:')\n",
        "  print(abs((sum(aa)-sum(ea))/len(aa)), abs((sum(aa_cn)-sum(ea_cn))/len(aa_cn)))\n",
        "  print('t value and p value :')\n",
        "  print(p1,p2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "race difference on Raw and CN data:\n",
            "0.04521691518263744 0.03932572493432523\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-24.943738180772687, pvalue=1.4610446201105612e-79) Ttest_relResult(statistic=-18.22503176661601, pvalue=1.2789578011826307e-52)\n",
            "race difference on Raw and CN data:\n",
            "0.06226927107069027 0.0579150360781525\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-38.831694571338595, pvalue=9.87549110514498e-129) Ttest_relResult(statistic=-33.469088427228854, pvalue=5.71714961932729e-111)\n",
            "race difference on Raw and CN data:\n",
            "0.04762017509955545 0.05283733143957083\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-23.820355241106842, pvalue=3.732281641473656e-75) Ttest_relResult(statistic=-22.10551130680492, pvalue=2.481160041233764e-68)\n",
            "race difference on Raw and CN data:\n",
            "0.03812963352164238 0.039024320354788\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-19.571734768839935, pvalue=4.2670226123119386e-58) Ttest_relResult(statistic=-15.474925753857805, pvalue=1.6958188647438285e-41)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-xV8OlU9UacY",
        "colab_type": "code",
        "outputId": "ab2b7c18-e524-4dec-9724-8b2a5e9295f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') & (sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European') & (sent_sent['Gender']=='female')]\n",
        "  #print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  print('race difference on Raw and CN data:')\n",
        "  print(abs((sum(aa)-sum(ea))/len(aa)), abs((sum(aa_cn)-sum(ea_cn))/len(aa_cn)))\n",
        "  print('t value and p value :')\n",
        "  print(p1,p2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "race difference on Raw and CN data:\n",
            "0.017832251820264967 0.014032763219116435\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=9.036385017234503, pvalue=1.1307572999312533e-17) Ttest_relResult(statistic=6.753846840262091, pvalue=6.03394816913532e-11)\n",
            "race difference on Raw and CN data:\n",
            "0.00975292484474843 0.007445103832855499\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=3.07329483033857, pvalue=0.0022836973755857963) Ttest_relResult(statistic=2.3653030189780466, pvalue=0.018561601120485743)\n",
            "race difference on Raw and CN data:\n",
            "0.02943942180953826 0.032589400394245606\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-16.240468979330785, pvalue=1.4235919380780754e-44) Ttest_relResult(statistic=-17.623152206074973, pvalue=3.5790289483384098e-50)\n",
            "race difference on Raw and CN data:\n",
            "0.011468743619508602 0.007270165407020305\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=4.786355911515621, pvalue=2.5123000440865755e-06) Ttest_relResult(statistic=2.959660791098189, pvalue=0.0032902243197567957)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mFapDcejVntk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using averaged sentiment embeddings"
      ]
    },
    {
      "metadata": {
        "id": "kRYsz7qiV-Ym",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Raw Sentence Embeddings\n",
        "from sklearn.decomposition import TruncatedSVD, randomized_svd\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def run_sif_benchmark(sentiment, sent1, sent2, model_str, freqs={}, a=0.001): \n",
        "    total_freq = sum(freqs.values())\n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        "    sen_list = EEC[EEC['Emotion']==sen]['Emotion word'].unique()\n",
        "    #average sentiment embedding based on several emotional words of the same sentiment\n",
        "    sen_embeddings = np.average([model[item] for item in sen_list if item in model.vocab], axis=0)    \n",
        "    tokens1 =  sent1.tokens\n",
        "    tokens2 =  sent2.tokens\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "        \n",
        "    embedding1 = np.array(np.average([model[token] for token in tokens1], axis=0, weights=weights1))\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 = np.array(np.average([model[token] for token in tokens2], axis=0, weights=weights2))\n",
        "    embedding2/= norm(embedding2)\n",
        "    proj1 = embedding1.dot(sen_embeddings)/norm(sen_embeddings)\n",
        "    proj2 = embedding2.dot(sen_embeddings)/norm(sen_embeddings)\n",
        "\n",
        "\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cOJbKd2kVwc5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#CN Sentence Embeddings\n",
        "def run_conceptor_benchmark(sentiment,sent1, sent2, model_str, freqs={}, a=0.001, alpha =2): \n",
        "    total_freq = sum(freqs.values())\n",
        "    \n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        "    sen_list = EEC[EEC['Emotion']==sen]['Emotion word'].unique()\n",
        "    sen_embeddings = np.average([model[item] for item in sen_list if item in model.vocab], axis = 0) \n",
        " #   print(sen_embeddings)\n",
        "    # SIF requires us to first collect all sentence embeddings and then perform \n",
        "    # common component analysis.\n",
        "        \n",
        "    tokens1 =  sent1.tokens\n",
        "    tokens2 =  sent2.tokens\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "        \n",
        "    embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n",
        "    embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n",
        "        \n",
        "\n",
        "    R = (cn_embeddings.T).dot(cn_embeddings) / cn_embeddings.shape[0]\n",
        "\n",
        "    \n",
        "    \n",
        "    C = R @ np.linalg.inv (R + alpha ** (-2) * np.eye(300))# calculate the conceptor matrix\n",
        "    \n",
        "    negC = np.eye(300) - C\n",
        "    #negC = np.eye(300) - SWC[model_str]\n",
        "    \n",
        "    \n",
        "    embedding1 = negC.dot(embedding1.T).T\n",
        "    embedding2 = negC.dot(embedding2.T).T\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 /= norm(embedding2)\n",
        "    proj1 = embedding1.dot(sen_embeddings)/norm(sen_embeddings)\n",
        "    proj2 = embedding2.dot(sen_embeddings)/norm(sen_embeddings)\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LFkCnIDDWdgY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cn_embeddings = []\n",
        "cn_embeddings.append([word2vec[word] for word in word_list if word in word2vec.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gutvU6j4V4LH",
        "colab_type": "code",
        "outputId": "dd6d043f-3ab2-4d35-8460-0060758ea2c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='male') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  print('race difference on Raw and CN data:')\n",
        "  print(abs((sum(aa)-sum(ea))/len(aa)), abs((sum(aa_cn)-sum(ea_cn))/len(aa_cn)))\n",
        "  print('t value and p value :')\n",
        "  print(p1,p2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "race difference on Raw and CN data:\n",
            "0.04662572981549439 0.020522541404676367\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=18.876431918735776, pvalue=2.8639485874507208e-55) Ttest_relResult(statistic=10.708957974466772, pvalue=2.4976579236435985e-23)\n",
            "race difference on Raw and CN data:\n",
            "0.04998477386310169 0.022366878710030926\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=18.281446420194115, pvalue=7.540233841077412e-53) Ttest_relResult(statistic=9.122866641605519, pvalue=5.946521198149247e-18)\n",
            "race difference on Raw and CN data:\n",
            "0.032158537610318456 0.015093970440087463\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=14.240858165282138, pvalue=1.3406594428461711e-36) Ttest_relResult(statistic=7.094972375095749, pvalue=7.2563526914607235e-12)\n",
            "race difference on Raw and CN data:\n",
            "0.036845289669755144 0.022301669105866284\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=15.365000261632002, pvalue=4.667010585304408e-41) Ttest_relResult(statistic=9.472993183364068, pvalue=4.250450526682309e-19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5EzflVRUWksZ",
        "colab_type": "code",
        "outputId": "d06676f8-d79f-472f-e7eb-e30b5b3dcd04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='female') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  print('race difference on Raw and CN data:')\n",
        "  print(abs((sum(aa)-sum(ea))/len(aa)), abs((sum(aa_cn)-sum(ea_cn))/len(aa_cn)))\n",
        "  print('t value and p value :')\n",
        "  print(p1,p2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "race difference on Raw and CN data:\n",
            "0.022654936036558167 0.001450832195656062\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=6.118688096111274, pvalue=2.5338502682791104e-09) Ttest_relResult(statistic=0.521135073553749, pvalue=0.6026031853281411)\n",
            "race difference on Raw and CN data:\n",
            "0.016162885661195545 0.0054722418761947115\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=4.115709755822177, pvalue=4.8209785226723784e-05) Ttest_relResult(statistic=-1.8135321778994684, pvalue=0.07060857039338449)\n",
            "race difference on Raw and CN data:\n",
            "0.006906583520517496 0.0005984480656133786\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=1.9404120112602472, pvalue=0.053134732784089776) Ttest_relResult(statistic=-0.21160293473467512, pvalue=0.8325403333239442)\n",
            "race difference on Raw and CN data:\n",
            "0.006719709066758323 0.003074133804024249\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=2.0707419456135723, pvalue=0.03911769868726408) Ttest_relResult(statistic=-1.1843412824527013, pvalue=0.23708393775577877)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X-idjANoWlWj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For GloVe data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([glove[word] for word in word_list if word in glove.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUewIufVWq6o",
        "colab_type": "code",
        "outputId": "99ce50c0-6890-4b9b-a915-f1273fe629fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='male') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  print('race difference on Raw and CN data:')\n",
        "  print(abs((sum(aa)-sum(ea))/len(aa)), abs((sum(aa_cn)-sum(ea_cn))/len(aa_cn)))\n",
        "  print('t value and p value :')\n",
        "  print(p1,p2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "race difference on Raw and CN data:\n",
            "0.06302937205867498 0.07254997581896215\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-33.357259918411145, pvalue=1.3931237562431747e-110) Ttest_relResult(statistic=-39.29094066300023, pvalue=3.4941102652479864e-130)\n",
            "race difference on Raw and CN data:\n",
            "0.07547536145795196 0.07282329005495813\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-41.60077802961862, pvalue=2.5381494998460953e-137) Ttest_relResult(statistic=-43.0374218848139, pvalue=1.2466506338301739e-141)\n",
            "race difference on Raw and CN data:\n",
            "0.12927816447736087 0.08611546453223826\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-48.7537846108828, pvalue=7.681814187382401e-158) Ttest_relResult(statistic=-40.89482112715392, pvalue=3.6169478117401684e-135)\n",
            "race difference on Raw and CN data:\n",
            "0.07036926528797599 0.06640802101071845\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-40.56185716860407, pvalue=3.8254505789367065e-134) Ttest_relResult(statistic=-40.22566073031065, pvalue=4.193127515734739e-133)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ljmJ9ZbDWrWM",
        "colab_type": "code",
        "outputId": "18e002c0-83c0-4095-c39f-79e568ff5d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='female') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  print('race difference on Raw and CN data:')\n",
        "  print(abs((sum(aa)-sum(ea))/len(aa)), abs((sum(aa_cn)-sum(ea_cn))/len(aa_cn)))\n",
        "  print('t value and p value :')\n",
        "  print(p1,p2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "race difference on Raw and CN data:\n",
            "0.04096830017299973 0.0585017183158558\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-24.210265683249048, pvalue=1.0870037112432228e-76) Ttest_relResult(statistic=-24.209658230257883, pvalue=1.092996416338596e-76)\n",
            "race difference on Raw and CN data:\n",
            "0.05871398460064565 0.06664692066125724\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-33.9296398672444, pvalue=1.4835937730648623e-112) Ttest_relResult(statistic=-29.540503472115283, pvalue=5.677199758529597e-97)\n",
            "race difference on Raw and CN data:\n",
            "0.12005264560672523 0.08061730147982855\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-30.262349001938492, pvalue=1.3167208516196352e-99) Ttest_relResult(statistic=-27.76839953643594, pvalue=2.1854457473446765e-90)\n",
            "race difference on Raw and CN data:\n",
            "0.054930740051117206 0.05865356050665282\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-33.26437526762301, pvalue=2.92274620423557e-110) Ttest_relResult(statistic=-26.9798608409489, pvalue=2.0999171278590803e-87)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PJ3AHZS3WzIb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For Fasttext data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([fasttext[word] for word in word_list if word in fasttext.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EEFY9sylWzfw",
        "colab_type": "code",
        "outputId": "75c615bd-e3f8-4500-cb81-ffe858576634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='male') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  print('race difference on Raw and CN data:')\n",
        "  print(abs((sum(aa)-sum(ea))/len(aa)), abs((sum(aa_cn)-sum(ea_cn))/len(aa_cn)))\n",
        "  print('t value and p value :')\n",
        "  print(p1,p2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "race difference on Raw and CN data:\n",
            "0.08636108169380927 0.0831680891788335\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-46.22573952963908, pvalue=7.524439130415276e-151) Ttest_relResult(statistic=-42.78894524234656, pvalue=6.822388265346177e-141)\n",
            "race difference on Raw and CN data:\n",
            "0.08247501382371565 0.07623093064691269\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-40.925204647373555, pvalue=2.9183785073658076e-135) Ttest_relResult(statistic=-37.277704932338466, pvalue=9.673073185204856e-124)\n",
            "race difference on Raw and CN data:\n",
            "0.0881266052142327 0.08976462966970668\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-43.95729469590564, pvalue=2.4441309482164621e-144) Ttest_relResult(statistic=-36.84358799927592, pvalue=2.525189955131654e-122)\n",
            "race difference on Raw and CN data:\n",
            "0.07361779760494179 0.07276741545335232\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-44.22799176331874, pvalue=3.9702270167735006e-145) Ttest_relResult(statistic=-34.96184279192713, pvalue=4.557814907621443e-116)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ADoqYIRFW3iY",
        "colab_type": "code",
        "outputId": "5ab1d6c7-f40a-4a48-8cd3-7f6a3470435d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='female') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  print('race difference on Raw and CN data:')\n",
        "  print(abs((sum(aa)-sum(ea))/len(aa)), abs((sum(aa_cn)-sum(ea_cn))/len(aa_cn)))\n",
        "  print('t value and p value :')\n",
        "  print(p1,p2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "race difference on Raw and CN data:\n",
            "0.038889994770878664 0.003719162069486158\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=12.255393635250222, pvalue=5.795978236005018e-29) Ttest_relResult(statistic=1.9190707658722383, pvalue=0.05579065224996515)\n",
            "race difference on Raw and CN data:\n",
            "0.025386111664488696 0.0070509051181963\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=7.1722054495814564, pvalue=4.445886453145004e-12) Ttest_relResult(statistic=-3.0243525116600662, pvalue=0.0026762586986232803)\n",
            "race difference on Raw and CN data:\n",
            "0.0001551391796906338 0.009183603829327548\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-0.0560981709042368, pvalue=0.9552957027578203) Ttest_relResult(statistic=-3.6677410283232916, pvalue=0.00028284707092270366)\n",
            "race difference on Raw and CN data:\n",
            "0.01722416185729896 0.008748072729915667\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=5.408570671112199, pvalue=1.1814760544160276e-07) Ttest_relResult(statistic=-3.5325122072161403, pvalue=0.0004669491288777481)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}